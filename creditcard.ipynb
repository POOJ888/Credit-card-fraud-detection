{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7294404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "credit_card_fraud.py\n",
    "====================\n",
    "Detect fraudulent credit-card transactions on a highly-imbalanced data set.\n",
    "\n",
    "Supported workflows\n",
    "-------------------\n",
    "1. Supervised classifiers + imbalance handling\n",
    "   • Logistic Regression          (plain / SMOTE / Random-Under-Sampling)\n",
    "   • Random Forest                (plain / SMOTE / RUS)\n",
    "\n",
    "2. Unsupervised anomaly detectors\n",
    "   • Isolation Forest\n",
    "   • Local Outlier Factor (LOF)\n",
    "\n",
    "Quick examples\n",
    "--------------\n",
    "# Train Logistic-Regression + SMOTE, evaluate, save model\n",
    "python credit_card_fraud.py --data data/creditcard.csv --target Class \\\n",
    "       --model lr_smote --test_size 0.2\n",
    "\n",
    "# Train Isolation Forest (unsupervised) on *all* data\n",
    "python credit_card_fraud.py --data data/creditcard.csv --model iso_forest\n",
    "\n",
    "# Predict on one new transaction (JSON), using a saved model\n",
    "python credit_card_fraud.py --predict sample_tx.json \\\n",
    "       --model_path models/fraud_model.pkl\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse, json, sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility helpers\n",
    "# ---------------------------------------------------------------------\n",
    "def load(path: str | Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def split_X_y(df: pd.DataFrame, target: str | None) -> Tuple[pd.DataFrame, pd.Series | None]:\n",
    "    if target is None:\n",
    "        return df, None\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found\")\n",
    "    return df.drop(columns=[target]), df[target]\n",
    "\n",
    "def num_preprocessor(cols) -> ColumnTransformer:\n",
    "    pipe = Pipeline(\n",
    "        [(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler())]\n",
    "    )\n",
    "    return ColumnTransformer([(\"num\", pipe, cols)])\n",
    "\n",
    "def get_supervised(name: str):\n",
    "    name = name.lower()\n",
    "    if name == \"lr\":\n",
    "        return LogisticRegression(max_iter=1000, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=500, n_jobs=-1, random_state=RANDOM_STATE\n",
    "        )\n",
    "    raise ValueError(\"Unknown supervised base model\")\n",
    "\n",
    "def build_pipeline(key: str, X: pd.DataFrame):\n",
    "    # Unsupervised\n",
    "    if key == \"iso_forest\":\n",
    "        return IsolationForest(contamination=0.001, random_state=RANDOM_STATE)\n",
    "    if key == \"lof\":\n",
    "        return LocalOutlierFactor(n_neighbors=20, novelty=True)\n",
    "\n",
    "    # Supervised + imbalance strategies\n",
    "    imb = None\n",
    "    if key.endswith(\"_smote\"):\n",
    "        base_key, imb = key.replace(\"_smote\", \"\"), \"smote\"\n",
    "    elif key.endswith(\"_rus\"):\n",
    "        base_key, imb = key.replace(\"_rus\", \"\"), \"rus\"\n",
    "    else:\n",
    "        base_key = key\n",
    "\n",
    "    clf = get_supervised(base_key)\n",
    "    pre = num_preprocessor(X.columns.tolist())\n",
    "\n",
    "    steps = [(\"pre\", pre)]\n",
    "    if imb == \"smote\":\n",
    "        steps.append((\"smote\", SMOTE(random_state=RANDOM_STATE)))\n",
    "    if imb == \"rus\":\n",
    "        steps.append((\"rus\", RandomUnderSampler(random_state=RANDOM_STATE)))\n",
    "    steps.append((base_key, clf))\n",
    "    return ImbPipeline(steps)\n",
    "\n",
    "def metrics(y_true, y_pred, y_prob) -> Dict[str, float]:\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    return dict(\n",
    "        precision=precision,\n",
    "        recall=recall,\n",
    "        f1=f1,\n",
    "        roc_auc=roc_auc_score(y_true, y_prob) if y_prob is not None else np.nan,\n",
    "        pr_auc=average_precision_score(y_true, y_prob)\n",
    "        if y_prob is not None\n",
    "        else np.nan,\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# CLI main\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    p = argparse.ArgumentParser(description=\"Credit-Card Fraud Detection\")\n",
    "    p.add_argument(\"--data\", type=str, help=\"CSV dataset path\")\n",
    "    p.add_argument(\n",
    "        \"--target\",\n",
    "        type=str,\n",
    "        default=\"Class\",\n",
    "        help=\"Fraud label column (1=fraud, 0=legit). Omit for unsupervised\",\n",
    "    )\n",
    "    p.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        default=\"lr_smote\",\n",
    "        help=\"lr, rf, lr_smote, rf_rus, iso_forest, lof\",\n",
    "    )\n",
    "    p.add_argument(\"--test_size\", type=float, default=0.2, help=\"Hold-out fraction\")\n",
    "    p.add_argument(\"--save_dir\", type=str, default=\"models\")\n",
    "    p.add_argument(\"--predict\", type=str, help=\"JSON file for single inference\")\n",
    "    p.add_argument(\"--model_path\", type=str, help=\"Saved model for --predict\")\n",
    "    args = p.parse_args()\n",
    "\n",
    "    # Inference-only path\n",
    "    if args.predict and args.model_path:\n",
    "        model = joblib.load(args.model_path)\n",
    "        record = pd.DataFrame([json.load(open(args.predict))])\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            prob = model.predict_proba(record)[0][1]\n",
    "            print(f\"Fraud probability: {prob:.4f}\")\n",
    "        else:\n",
    "            score = -model.decision_function(record)[0]\n",
    "            print(f\"Anomaly score: {score:.4f}  (higher = more anomalous)\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Training / evaluation path\n",
    "    # -----------------------------------------------------------------\n",
    "    if not args.data:\n",
    "        p.error(\"--data is required for training\")\n",
    "\n",
    "    df = load(args.data)\n",
    "    X, y = split_X_y(df, None if args.model in {\"iso_forest\", \"lof\"} else args.target)\n",
    "\n",
    "    model = build_pipeline(args.model, X)\n",
    "\n",
    "    if y is None:\n",
    "        # Unsupervised: fit on entire data\n",
    "        model.fit(X)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=args.test_size,\n",
    "            stratify=y,\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = (\n",
    "            model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        )\n",
    "        m = metrics(y_test, y_pred, y_prob)\n",
    "        print(\n",
    "            \"Precision: {precision:.3f}  Recall: {recall:.3f}  \"\n",
    "            \"F1: {f1:.3f}  ROC_AUC: {roc_auc:.3f}  PR_AUC: {pr_auc:.3f}\".format(**m)\n",
    "        )\n",
    "\n",
    "    # Save model\n",
    "    Path(args.save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    fp = Path(args.save_dir) / \"fraud_model.pkl\"\n",
    "    joblib.dump(model, fp)\n",
    "    print(f\"Model saved ➜ {fp.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542712c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
